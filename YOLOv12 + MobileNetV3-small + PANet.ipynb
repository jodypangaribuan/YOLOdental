{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN41R+zDFB7MmvXUgxq++VL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# ***YOLOv12 + MobileNetV3-small + PANet***"],"metadata":{"id":"HFQ7ut2XHXxQ"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Janu0QKTENXS","executionInfo":{"status":"error","timestamp":1763387863136,"user_tz":-420,"elapsed":20817,"user":{"displayName":"jody","userId":"03037885248538497141"}},"outputId":"8b9ca23a-c6b7-4033-b62e-8b67b38c7915"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","‚úÖ Dataset berhasil diunduh: /content/dental-caries-10/data.yaml\n","Struktur dataset: ['train', 'valid', 'README.dataset.txt', 'data.yaml', 'README.roboflow.txt', 'test']\n","‚úÖ Custom YAML disimpan: /content/yolo12m_mobilenetv3-small_panet.yaml\n","Ultralytics 8.3.228 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dental-caries-10/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/yolo12m_mobilenetv3-small_panet.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_icdas_mnetv3-small_panet2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=False, profile=False, project=runs/pure, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/pure/train_icdas_mnetv3-small_panet2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1    927008  ultralytics.nn.modules.block.TorchVision     ['mobilenet_v3_small', 'DEFAULT', True, 2, True]\n","  1                   0  1         0  ultralytics.nn.modules.conv.Index            [3]                           \n","  2                   1  1      6656  ultralytics.nn.modules.conv.Conv             [24, 256, 1, 1]               \n","  3                   0  1         0  ultralytics.nn.modules.conv.Index            [8]                           \n","  4                   3  1     25600  ultralytics.nn.modules.conv.Conv             [48, 512, 1, 1]               \n","  5                   0  1         0  ultralytics.nn.modules.conv.Index            [12]                          \n","  6                   5  1     50176  ultralytics.nn.modules.conv.Conv             [96, 512, 1, 1]               \n","  7                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n","  8             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n","  9                  -1  1   1248768  ultralytics.nn.modules.block.A2C2f           [1024, 512, 1, False, -1]     \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 2]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n"," 13                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 14             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1   1183232  ultralytics.nn.modules.block.A2C2f           [768, 512, 1, False, -1]      \n"," 16                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n"," 17             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n"," 19        [12, 15, 18]  1   1416421  ultralytics.nn.modules.head.Detect           [7, [256, 512, 512]]          \n","YOLO12m_mobilenetv3-small_panet summary: 271 layers, 9,796,869 parameters, 9,796,853 gradients, 25.4 GFLOPs\n","\n","Freezing layer 'model.19.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1398.7¬±451.5 MB/s, size: 40.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dental-caries-10/train/labels.cache... 7234 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7234/7234 12.8Mit/s 0.0s\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/dental-caries-10/train/images/anonymous-frontalView-1727682033413_jpg.rf.83115b62e1b560431399c0fa4d3cb0ff.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/dental-caries-10/train/images/anonymous-frontalView-1727682033413_jpg.rf.91fd1039ebfaf7e65d0222c50eb09048.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/dental-caries-10/train/images/anonymous_003-007-1319-00_1733466947980_Left_Lateral_View_jpg.rf.bffc238adbebbd87b4d4560f27ab94aa.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/dental-caries-10/train/images/anonymous_003-007-1319-00_1733466947980_Left_Lateral_View_jpg.rf.e0a66ca6653f78dafd11d2e3031e1b54.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/dental-caries-10/train/images/anonymous_003_007_344_00_1728027849334_Left_Lateral_View_jpg.rf.1e7bd84712fbb9d528ca34ea816bd4ae.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/dental-caries-10/train/images/anonymous_003_007_344_00_1728027849334_Left_Lateral_View_jpg.rf.3de4ad7d8c84ec7df58478d4a93e2ff9.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 371.0¬±268.0 MB/s, size: 45.6 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dental-caries-10/valid/labels.cache... 500 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 500/500 526.4Kit/s 0.0s\n","\u001b[34m\u001b[1mval: \u001b[0m/content/dental-caries-10/valid/images/anonymous_003-008-826-00_1729951922030_Maxillary_Occlusal_View_jpg.rf.b120d8b7b185dfce14fd7925a36462c2.jpg: 1 duplicate labels removed\n","Plotting labels to /content/runs/pure/train_icdas_mnetv3-small_panet2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 93 weight(decay=0.0), 118 weight(decay=0.0005), 117 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/runs/pure/train_icdas_mnetv3-small_panet2\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K: 0% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0/453  8.2s\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3316312399.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mtrain_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_YAML\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Training selesai! Model terbaik: runs/pure/train_icdas_mnetv3-small_panet/weights/best.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3316312399.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, data_yaml, project_name, epochs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_yaml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_icdas_mnetv3-small_panet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     results = model.train(\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_yaml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mni\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlast_opt_step\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Install required packages (for Google Colab)\n","!pip install -q ultralytics roboflow\n","\n","import os\n","from pathlib import Path\n","import yaml\n","from roboflow import Roboflow\n","from ultralytics import YOLO\n","\n","# Konfigurasi Roboflow\n","API_KEY = \"QOd5ldAdjiaehHn5m6WC\"\n","WORKSPACE = \"dentalogic8\"\n","PROJECT_ID = \"dental-caries-7kttb\"\n","VERSION_NUM = 10\n","\n","# Download Dataset\n","rf = Roboflow(api_key=API_KEY)\n","project = rf.workspace(WORKSPACE).project(PROJECT_ID)\n","dataset = project.version(VERSION_NUM).download(\"yolov12\")\n","\n","DATASET_DIR = Path(f\"/content/dental-caries-{VERSION_NUM}\")\n","DATA_YAML = DATASET_DIR / \"data.yaml\"\n","\n","# Verifikasi download\n","if DATA_YAML.exists():\n","    print(f\"‚úÖ Dataset berhasil diunduh: {DATA_YAML}\")\n","    print(f\"Struktur dataset: {os.listdir(DATASET_DIR)}\")\n","else:\n","    raise FileNotFoundError(\"Dataset gagal diunduh. Periksa koneksi dan kredensial Roboflow.\")\n","\n","# Custom YAML untuk YOLOv12 dengan MobileNetV3-Small backbone via TorchVision\n","custom_yaml_content = \"\"\"\n","nc: 7  # number of classes\n","scales:  # model compound scaling constants\n","  n: [0.50, 0.25, 1024]\n","  s: [0.50, 0.50, 1024]\n","  m: [0.50, 1.00, 512]\n","  l: [1.00, 1.00, 512]\n","  x: [1.00, 1.50, 512]\n","\n","# MobileNetV3-Small backbone via TorchVision (adapted to match original YOLOv12 outputs)\n","backbone:\n","  # [from, repeats, module, args]\n","  - [-1, 1, TorchVision, [0, mobilenet_v3_small, DEFAULT, True, 2, True]]  # 0: MobileNetV3-Small\n","  - [0, 1, Index, [24, 3]]  # 1: P3 raw (24ch, /8)\n","  - [1, 1, Conv, [256, 1, 1]]  # 2: P3 projected (256ch, /8)\n","  - [0, 1, Index, [48, 8]]  # 3: P4 raw (48ch, /16)\n","  - [3, 1, Conv, [512, 1, 1]]  # 4: P4 projected (512ch, /16)\n","  - [0, 1, Index, [96, 12]]  # 5: P5 raw (96ch, /32)\n","  - [5, 1, Conv, [1024, 1, 1]]  # 6: P5 projected (1024ch, /32)\n","\n","# YOLO12 head (adapted indices to match projected features: P3=2, P4=4, P5=6)\n","head:\n","  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]  # 7: up P5\n","  - [[-1, 4], 1, Concat, [1]]  # 8: cat up P5 + P4\n","  - [-1, 2, A2C2f, [512, False, -1]]  # 9: refined P4\n","  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]  # 10: up refined P4\n","  - [[-1, 2], 1, Concat, [1]]  # 11: cat up P4 + P3\n","  - [-1, 2, A2C2f, [256, False, -1]]  # 12: refined P3\n","  - [-1, 1, Conv, [256, 3, 2]]  # 13: down P3 to P4\n","  - [[-1, 9], 1, Concat, [1]]  # 14: cat down P3 + refined P4\n","  - [-1, 2, A2C2f, [512, False, -1]]  # 15: refined P4\n","  - [-1, 1, Conv, [512, 3, 2]]  # 16: down P4 to P5\n","  - [[-1, 6], 1, Concat, [1]]  # 17: cat down P4 + P5\n","  - [-1, 2, C3k2, [1024, True]]  # 18: refined P5\n","  - [[12, 15, 18], 1, Detect, [nc]]  # Detect(P3, P4, P5)\n","\"\"\"\n","\n","# Simpan YAML ke file\n","custom_yaml_path = Path(\"/content/yolo12n_mobilenetv3-small_panet.yaml\")\n","with open(custom_yaml_path, \"w\") as f:\n","    f.write(custom_yaml_content)\n","print(f\"‚úÖ Custom YAML disimpan: {custom_yaml_path}\")\n","\n","# Inisialisasi model dengan custom YAML\n","model = YOLO(str(custom_yaml_path))\n","\n","def train_model(model, data_yaml, project_name=\"train_icdas_mnetv3-small_panet\", epochs=50):\n","    results = model.train(\n","        data=data_yaml,\n","        imgsz=640,\n","        epochs=epochs,\n","        batch=16,\n","        device=0,\n","        deterministic=True,\n","        project=\"runs/pure\",\n","        name=project_name,\n","        pretrained=False  # Backbone pretrained via DEFAULT, head from scratch\n","    )\n","    return results\n","\n","train_results = train_model(model, DATA_YAML)\n","print(\"‚úÖ Training selesai! Model terbaik: runs/pure/train_icdas_mnetv3-small_panet/weights/best.pt\")"]}]}